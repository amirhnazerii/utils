{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Chatbot memory**\n",
        "\n",
        "**Introduction:**\n",
        "The main focus is on handling prompts and maintaining context within the model's attention window.\n",
        "\n",
        "**Objective:**\n",
        "The aim is to address issues related to flattening conversation elements, catching exceptions when prompts exceed the model's attention window, and selecting appropriate truncation methods to preserve context.\n",
        "\n",
        "**Procedure:**\n",
        "1. **Flattening the Conversation:**\n",
        "   - Flatten the list of conversational elements using delimiters, such as two new lines (e.g. `\"\".join()` or `custom flattener`).\n",
        "\n",
        "2. **Handling Exceptions:**\n",
        "   - Catch exceptions thrown by the LLM when prompts exceed its attention window.\n",
        "\n",
        "3. **Truncation Methods:**\n",
        "   - **Simple Truncation:** Remove the oldest element, which may result in losing important context, such as the system prompt.\n",
        "   - **Selective Truncation:** Retain the system prompt while removing recent conversational turns, ensuring continuity of context.\n",
        "\n",
        "**Important Points:**\n",
        "- The choice of truncation method impacts the relevance and continuity of the LLM's responses. Retaining the system prompt can help maintain the LLM's identity and response consistency."
      ],
      "metadata": {
        "id": "8Q838AVn3BEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def installer():\n",
        "    !pip install openai==0.28\n",
        "    # !pip install --upgrade openai\n",
        "installer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN8iedLq3VzJ",
        "outputId": "5f67ec87-3887-4c86-c2c5-8938308dbc71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JFJaQyi2-EGC"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac0be_OciY7c",
        "outputId": "f942d04b-0191-47b5-b0bc-b9609af70dc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 0.28.0\n",
            "Summary: Python client library for the OpenAI API\n",
            "Home-page: https://github.com/openai/openai-python\n",
            "Author: OpenAI\n",
            "Author-email: support@openai.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, requests, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WJ0zTNVt0ZD4"
      },
      "outputs": [],
      "source": [
        "openai.api_key =  \"voc-1126793339126677340548166ad2296cf93d9.28124368\"\n",
        "openai.api_base = \"https://openai.vocareum.com/v1\" # Remove this if using personal key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "N_C65IHa0ZD6"
      },
      "outputs": [],
      "source": [
        "# Decoding parameters\n",
        "TEMPERATURE = 0.0\n",
        "MAX_TOKENS = 3950  # Increased to simulate LLM with smaller attention window\n",
        "TOP_P = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GGXSFlArmKt7"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"You expert at games of chance.\n",
        "End every response with double exclamation points!!\"\"\"\n",
        "\n",
        "USER_NAME = \"User\"\n",
        "AI_NAME = \"AI Assistant\"\n",
        "NEW_INTERACTION_DELIMITER = \"\\n\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic4juggvKEB8"
      },
      "source": [
        "# Creating a chat bot with memory\n",
        "Using the basic `openai.Completion` API to understand where the memory \"lives\" in the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dVHDhMmZmLHF"
      },
      "outputs": [],
      "source": [
        "def query_openai(prompt):\n",
        "\n",
        "    # openai.Completion is no longer supported in openai>=1.0.0\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        top_p=TOP_P,\n",
        "    )\n",
        "    time.sleep(5) # to avoid rate limit errors\n",
        "    if \"error\" in response:\n",
        "        raise openai.InvalidRequestError(response[\"error\"], param=None)\n",
        "    else:\n",
        "        return response.choices[0].text.strip().strip(\"\\n\")\n",
        "\n",
        "\n",
        "def get_system_prompt(input_str=SYSTEM_PROMPT):\n",
        "    return [f\"System:{input_str}\"]\n",
        "\n",
        "\n",
        "def get_convo(input_str, convo):\n",
        "    if not convo:\n",
        "        convo = get_system_prompt()\n",
        "    user_input_str = f\"{USER_NAME}: {input_str}\"\n",
        "    response_trigger = f\"{AI_NAME}: \"\n",
        "    convo.extend([user_input_str, response_trigger])\n",
        "    return convo\n",
        "\n",
        "\n",
        "def get_response(input_str, convo, use_simple_truncation, verbose):\n",
        "    \"\"\"\n",
        "    Generate a response from an LLM based on user input_str and conversation history.\n",
        "\n",
        "    Parameters:\n",
        "    input_str (str): The user's current input_str or query to the language model.\n",
        "    convo (list of str): A list representing the history of the conversation.\n",
        "    use_simple_truncation (bool): A flag to determine whether to use a simple truncation\n",
        "                                  method for managing conversation length.\n",
        "    verbose (bool): A flag to determine if entire convo history should be printed.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated response from the language model based on the current input_str and\n",
        "         the conversation history.\n",
        "    \"\"\"\n",
        "    convo = get_convo(input_str, convo)\n",
        "\n",
        "    print(convo)\n",
        "\n",
        "    # Try to prompt model and catch if the prompt exceeds the attention window\n",
        "    first_try = True\n",
        "    atten_window_all_used_up = False\n",
        "    while first_try or atten_window_all_used_up:\n",
        "\n",
        "        # Convo list flattened into string to feed to model - Method 1\n",
        "        flattened_convo = \"\"\n",
        "        def flattener(empty_str, strings_list):\n",
        "            for string in strings_list:\n",
        "                empty_str += string\n",
        "            return empty_str\n",
        "        flattened_convo = flattener(flattened_convo, convo)\n",
        "\n",
        "        # Convo list flattened into string to feed to model - Method 2\n",
        "        # flattened_convo = NEW_INTERACTION_DELIMITER.join(convo)\n",
        "\n",
        "        try:\n",
        "            first_try = False\n",
        "            response = query_openai(flattened_convo)\n",
        "            atten_window_all_used_up = False\n",
        "\n",
        "        except openai.OpenAIError as e:\n",
        "            atten_window_all_used_up = True\n",
        "            if verbose:\n",
        "                print(\"** ATTEN_WINDOW ALL USED UP **\")\n",
        "                print(f\"OpenAI Error: {repr(e)}\\n\")\n",
        "\n",
        "            if not convo:\n",
        "                return [\n",
        "                    \"Our Error: System prompt is using up too many tokens of the attention window\"\n",
        "                ]\n",
        "\n",
        "            # We can recover from over-allocation of atten_window by removing\n",
        "            # components from history.\n",
        "            if use_simple_truncation:\n",
        "                # Just remove oldest element in convo\n",
        "                convo = convo[1:]  # TODO\n",
        "\n",
        "            else:\n",
        "                # Remove the oldest User or AI convo turn, while retaining\n",
        "                # system prompt\n",
        "                convo = convo[:1] + convo[2:] # TODO\n",
        "\n",
        "    # Add the LLM response to the response_trigger\n",
        "    convo[-1] += response\n",
        "    if verbose:\n",
        "        print(NEW_INTERACTION_DELIMITER.join(convo))\n",
        "    else:\n",
        "        print(f\"{USER_NAME}: {input_str}\")\n",
        "        print(f\"{AI_NAME}: {response}\")\n",
        "\n",
        "    return convo\n",
        "\n",
        "\n",
        "def chat(user_query, convo=[], use_simple_truncation=False, verbose=False):\n",
        "    convo = get_response(user_query, convo, use_simple_truncation, verbose)\n",
        "    return convo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC6CGoDKK5l9"
      },
      "source": [
        "## Testing our Chat bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7MFIxTMRmpL0"
      },
      "outputs": [],
      "source": [
        "user_inputs = [\n",
        "    \"What cards game has the best odds of winning?\",\n",
        "    \"What are the odds of winning it?\",\n",
        "    \"What is the best hand to be dealt?\",\n",
        "    \"What is the next most likely game to win?\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0p61acSK-bW"
      },
      "source": [
        "### Simple convo truncation method\n",
        "Model remembers prior convo but **forgets to** always ends in exclamation points!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Udi8FpJW8Hf",
        "outputId": "36f987a0-d453-442a-a836-7b16f0834c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** Convo turn 0 ****\n",
            "['System:You expert at games of chance.\\nEnd every response with double exclamation points!!', 'User: What cards game has the best odds of winning?', 'AI Assistant: ']\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: Blackjack is known for having some of the best odds in a casino!!\n",
            "\n",
            "**** Convo turn 1 ****\n",
            "['System:You expert at games of chance.\\nEnd every response with double exclamation points!!', 'User: What cards game has the best odds of winning?', 'AI Assistant: Blackjack is known for having some of the best odds in a casino!!', 'User: What are the odds of winning it?', 'AI Assistant: ']\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: Blackjack is known for having some of the best odds in a casino!!\n",
            "\n",
            "User: What are the odds of winning it?\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack can vary depending on the specific rules and strategies used, but on average, the house edge is around 1%!! So if you play your cards right, you have a good chance of coming out on top!!\n",
            "\n",
            "**** Convo turn 2 ****\n",
            "['System:You expert at games of chance.\\nEnd every response with double exclamation points!!', 'User: What cards game has the best odds of winning?', 'AI Assistant: Blackjack is known for having some of the best odds in a casino!!', 'User: What are the odds of winning it?', 'AI Assistant: The odds of winning at blackjack can vary depending on the specific rules and strategies used, but on average, the house edge is around 1%!! So if you play your cards right, you have a good chance of coming out on top!!', 'User: What is the best hand to be dealt?', 'AI Assistant: ']\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: Blackjack is known for having some of the best odds in a casino!!\n",
            "\n",
            "User: What are the odds of winning it?\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack can vary depending on the specific rules and strategies used, but on average, the house edge is around 1%!! So if you play your cards right, you have a good chance of coming out on top!!\n",
            "\n",
            "User: What is the best hand to be dealt?\n",
            "\n",
            "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3 to 2 odds, giving you a higher chance of winning!! However, it's important to remember that luck and skill both play a role in the game, so it's always important to play responsibly and have fun!!\n",
            "\n",
            "**** Convo turn 3 ****\n",
            "['System:You expert at games of chance.\\nEnd every response with double exclamation points!!', 'User: What cards game has the best odds of winning?', 'AI Assistant: Blackjack is known for having some of the best odds in a casino!!', 'User: What are the odds of winning it?', 'AI Assistant: The odds of winning at blackjack can vary depending on the specific rules and strategies used, but on average, the house edge is around 1%!! So if you play your cards right, you have a good chance of coming out on top!!', 'User: What is the best hand to be dealt?', \"AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3 to 2 odds, giving you a higher chance of winning!! However, it's important to remember that luck and skill both play a role in the game, so it's always important to play responsibly and have fun!!\", 'User: What is the next most likely game to win?', 'AI Assistant: ']\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x7aa5f2f39b70> JSON: {\n",
            "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4164 tokens (214 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
            "  \"type\": \"invalid_request_error\",\n",
            "  \"param\": null,\n",
            "  \"code\": null\n",
            "}, param=None, code=None, http_status=None, request_id=None)\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x7aa5f2f39b70> JSON: {\n",
            "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4146 tokens (196 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
            "  \"type\": \"invalid_request_error\",\n",
            "  \"param\": null,\n",
            "  \"code\": null\n",
            "}, param=None, code=None, http_status=None, request_id=None)\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x7aa5f3f93f60> JSON: {\n",
            "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4134 tokens (184 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
            "  \"type\": \"invalid_request_error\",\n",
            "  \"param\": null,\n",
            "  \"code\": null\n",
            "}, param=None, code=None, http_status=None, request_id=None)\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x7aa5f3f80630> JSON: {\n",
            "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4117 tokens (167 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
            "  \"type\": \"invalid_request_error\",\n",
            "  \"param\": null,\n",
            "  \"code\": null\n",
            "}, param=None, code=None, http_status=None, request_id=None)\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x7aa5f2f07880> JSON: {\n",
            "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4107 tokens (157 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
            "  \"type\": \"invalid_request_error\",\n",
            "  \"param\": null,\n",
            "  \"code\": null\n",
            "}, param=None, code=None, http_status=None, request_id=None)\n",
            "\n",
            "User: What is the best hand to be dealt?\n",
            "\n",
            "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3 to 2 odds, giving you a higher chance of winning!! However, it's important to remember that luck and skill both play a role in the game, so it's always important to play responsibly and have fun!!\n",
            "\n",
            "User: What is the next most likely game to win?\n",
            "\n",
            "AI Assistant: The next most likely game to win in a casino is craps. This game has a low house edge and offers a variety of betting options, making it a popular choice among players. However, as with any casino game, it's important to understand the rules and strategies before playing to increase your chances of winning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "convo = []\n",
        "verbose = True\n",
        "simple_truncation = True\n",
        "for i, input in enumerate(user_inputs):\n",
        "    print(f\"**** Convo turn {i} ****\")\n",
        "    convo = chat(\n",
        "        input, convo=convo, use_simple_truncation=simple_truncation, verbose=verbose\n",
        "    )\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqcax0zmLs9X"
      },
      "source": [
        "#### What is happening?\n",
        "Peaking under hood to see the full conversation as it grows\n",
        "\n",
        "NOTE: In **convo turn 3** we remove the system prompt to avoid exceeding the LLM attention window\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58SqyIARWT8c",
        "outputId": "984a59ef-495e-457a-e54f-ddb3e3b88352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**** Convo turn 0 ****\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
            "\n",
            "**** Convo turn 1 ****\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
            "\n",
            "User: What are the odds of winning it?\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
            "\n",
            "**** Convo turn 2 ****\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
            "\n",
            "User: What are the odds of winning it?\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
            "\n",
            "User: What is the best hand to be dealt?\n",
            "\n",
            "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
            "\n",
            "**** Convo turn 3 ****\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: This model's maximum context length is 4097 tokens, however you requested 4139 tokens (189 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: This model's maximum context length is 4097 tokens, however you requested 4121 tokens (171 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: This model's maximum context length is 4097 tokens, however you requested 4109 tokens (159 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\n",
            "\n",
            "User: What are the odds of winning it?\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
            "\n",
            "User: What is the best hand to be dealt?\n",
            "\n",
            "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
            "\n",
            "User: What is the next most likely game to win?\n",
            "\n",
            "AI Assistant: The next most likely game to win would depend on the specific casino and its games. However, some popular games with good odds of winning include baccarat, craps, and video poker. It's always a good idea to research the odds and strategies for different games before playing.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "convo = []\n",
        "verbose = True\n",
        "simple_truncation = True\n",
        "for i, input in enumerate(user_inputs):\n",
        "    print(f\"**** Convo turn {i} ****\")\n",
        "    convo = chat(\n",
        "        input, convo=convo, use_simple_truncation=simple_truncation, verbose=verbose\n",
        "    )\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDY-XBnUNKUL"
      },
      "source": [
        "### Retaining System prompt truncation method\n",
        "Model remembers most of prior convo and **remembers to** always ends in exclamation points!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHJnH0YLJKMX",
        "outputId": "5eea21fe-e65c-4628-a43b-b2fe4bbb3093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**** Convo turn 0 ****\n",
            "User: What cards game has the best odds of winning?\n",
            "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
            "\n",
            "**** Convo turn 1 ****\n",
            "User: What are the odds of winning it?\n",
            "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
            "\n",
            "**** Convo turn 2 ****\n",
            "User: What is the best hand to be dealt?\n",
            "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
            "\n",
            "**** Convo turn 3 ****\n",
            "User: What is the next most likely game to win?\n",
            "AI Assistant: The next most likely game to win would depend on your personal preferences and skills. Some popular games of chance include poker, roulette, and baccarat. However, with your expertise, you may have a higher chance of winning at any game you choose!!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "convo = []\n",
        "verbose = False\n",
        "for i, input in enumerate(user_inputs):\n",
        "    print(f\"**** Convo turn {i} ****\")\n",
        "    convo = chat(input, convo=convo, verbose=verbose)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBRZFXA6MltU"
      },
      "source": [
        "#### What is happening?\n",
        "Peaking under hood to see full convo as it grows\n",
        "\n",
        "NOTE: In **convo turn 3** we remove the oldest **convo turns**, but retain the system prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbSxLx9_M4lw",
        "outputId": "7f1eda93-8c09-4cae-8a4a-e47333e49105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**** Convo turn 0 ****\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
            "\n",
            "**** Convo turn 1 ****\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
            "\n",
            "User: What are the odds of winning it?\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
            "\n",
            "**** Convo turn 2 ****\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "User: What cards game has the best odds of winning?\n",
            "\n",
            "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
            "\n",
            "User: What are the odds of winning it?\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
            "\n",
            "User: What is the best hand to be dealt?\n",
            "\n",
            "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
            "\n",
            "**** Convo turn 3 ****\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: This model's maximum context length is 4097 tokens, however you requested 4139 tokens (189 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: This model's maximum context length is 4097 tokens, however you requested 4127 tokens (177 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\n",
            "\n",
            "** ATTEN_WINDOW ALL USED UP **\n",
            "OpenAI Error: This model's maximum context length is 4097 tokens, however you requested 4103 tokens (153 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\n",
            "\n",
            "System:You expert at games of chance.\n",
            "End every response with double exclamation points!!\n",
            "\n",
            "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
            "\n",
            "User: What is the best hand to be dealt?\n",
            "\n",
            "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
            "\n",
            "User: What is the next most likely game to win?\n",
            "\n",
            "AI Assistant: The next most likely game to win would depend on your personal preferences and skills. Some popular games of chance include poker, roulette, and baccarat. However, with your expertise, you may have a higher chance of winning at any game you choose!!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "convo = []\n",
        "verbose = True\n",
        "for i, input in enumerate(user_inputs):\n",
        "    print(f\"**** Convo turn {i} ****\")\n",
        "    convo = chat(input, convo=convo, verbose=verbose)\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}